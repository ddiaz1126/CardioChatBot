{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836fed4e",
   "metadata": {},
   "source": [
    "# Embedding Model\n",
    "- Notebook to test embedding model\n",
    "- Model: all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f904fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99196560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1bdab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt categories and labels from JSON\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path.cwd()\n",
    "data_root = base / 'data' / 'prompts'\n",
    "if not data_root.exists():\n",
    "    data_root = base.parent / 'data' / 'prompts'\n",
    "\n",
    "prompt_categories = json.loads((data_root / 'prompt_examples.json').read_text(encoding='utf-8'))\n",
    "prompt_labels_map = json.loads((data_root / 'prompt_labels.json').read_text(encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "847f81d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total example prompts: 105\n"
     ]
    }
   ],
   "source": [
    "# Flatten all example prompts with their categories\n",
    "all_prompt_categories = prompt_categories\n",
    "\n",
    "category_examples = []\n",
    "category_labels = []\n",
    "\n",
    "for category, examples in all_prompt_categories.items():\n",
    "    category_examples.extend(examples)\n",
    "    category_labels.extend([category] * len(examples))\n",
    "\n",
    "print(f\"Total example prompts: {len(category_examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe1afb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all example prompts (normalize for cosine similarity)\n",
    "example_embeddings = model.encode(category_examples, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d17af59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created FAISS IP index with 105 example prompts\n",
      "Embedding dimension: 384\n",
      "Categories available: ['volume_consistency', 'distance_progression', 'pace_trends', 'heart_rate_analysis', 'workout_type', 'recovery_patterns', 'performance_metrics']\n"
     ]
    }
   ],
   "source": [
    "# Build FAISS index with cosine similarity (inner product on normalized vectors)\n",
    "dimension = example_embeddings.shape[1]  # 384 for all-MiniLM-L6-v2\n",
    "index_ip = faiss.IndexFlatIP(dimension)\n",
    "index_ip.add(example_embeddings)\n",
    "\n",
    "print(f\"Created FAISS IP index with {len(category_examples)} example prompts\")\n",
    "print(f\"Embedding dimension: {dimension}\")\n",
    "print(f\"Categories available: {list(all_prompt_categories.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd0fda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_user_prompt(user_prompt, k=5, min_top_similarity=0.35, temperature=0.07, other_category_count=3):\n",
    "    \"\"\"\n",
    "    Classify a user prompt into cardio data analysis categories\n",
    "\n",
    "    Parameters:\n",
    "    - user_prompt: str, the question/prompt from the user\n",
    "    - k: int, number of nearest neighbors to consider\n",
    "    - min_top_similarity: float or None, reject if top similarity is below this\n",
    "    - temperature: float, softmax temperature for similarity weighting\n",
    "    - other_category_count: int, number of alternative categories to return\n",
    "\n",
    "    Returns:\n",
    "    - dict with classification results\n",
    "    \"\"\"\n",
    "    # Encode the user prompt\n",
    "    prompt_embedding = model.encode([user_prompt], normalize_embeddings=True)\n",
    "\n",
    "    # Search for k nearest neighbors\n",
    "    similarities, indices = index_ip.search(prompt_embedding, k)\n",
    "\n",
    "    # Get the categories of nearest neighbors\n",
    "    nearest_categories = [category_labels[idx] for idx in indices[0]]\n",
    "    nearest_similarities = similarities[0]\n",
    "\n",
    "    # Distance-aware class scoring using softmax over similarities\n",
    "    sims = np.array(nearest_similarities, dtype=float)\n",
    "    temp = max(float(temperature), 1e-6)\n",
    "    weights = np.exp((sims - sims.max()) / temp)\n",
    "\n",
    "    scores = {}\n",
    "    for i, cat in enumerate(nearest_categories):\n",
    "        scores[cat] = scores.get(cat, 0.0) + weights[i]\n",
    "\n",
    "    predicted_category = max(scores, key=scores.get)\n",
    "    total_score = sum(scores.values())\n",
    "    confidence = scores[predicted_category] / total_score if total_score else 0.0\n",
    "\n",
    "    # Rejection logic based on similarity\n",
    "    top_similarity = float(sims[0]) if len(sims) else 0.0\n",
    "\n",
    "    rejected = False\n",
    "    if min_top_similarity is not None and top_similarity < min_top_similarity:\n",
    "        rejected = True\n",
    "\n",
    "    if rejected:\n",
    "        predicted_category = \"other\"\n",
    "\n",
    "    # Alternative categories (exclude best prediction)\n",
    "    other_categories = []\n",
    "    for cat, score in scores.items():\n",
    "        if cat == predicted_category:\n",
    "            continue\n",
    "        other_categories.append({\n",
    "            'category': cat,\n",
    "            'confidence': (score / total_score if total_score else 0.0)\n",
    "        })\n",
    "\n",
    "    other_categories.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    other_categories = other_categories[:other_category_count]\n",
    "\n",
    "    return {\n",
    "        'predicted_category': predicted_category,\n",
    "        'confidence': confidence,\n",
    "        'rejected': rejected,\n",
    "        'top_similarity': top_similarity,\n",
    "        'other_categories': other_categories,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40a50795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'poop'\n",
      "Predicted category: other\n",
      "Confidence: 0.721\n",
      "Other categories:\n",
      "- workout_type: 0.721\n",
      "- pace_trends: 0.150\n",
      "- recovery_patterns: 0.129\n"
     ]
    }
   ],
   "source": [
    "# Try your own query\n",
    "user_query = \"poop\"\n",
    "result = classify_user_prompt(user_query)\n",
    "print(f\"Prompt: '{user_query}'\")\n",
    "print(f\"Predicted category: {result['predicted_category']}\")\n",
    "print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "print(\"Other categories:\")\n",
    "for item in result['other_categories']:\n",
    "    print(f\"- {item['category']}: {item['confidence']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
